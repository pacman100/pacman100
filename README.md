<div id="header" align="center">
  <img src="https://media.giphy.com/media/CVtNe84hhYF9u/giphy.gif" width="100"/>
  <div id="badges">
    <a href="https://www.linkedin.com/in/sourab-m/">
      <img src="https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn Badge"/>
    </a>
    <a href="https://huggingface.co/smangrul">
      <img src="https://img.shields.io/badge/Hugging Face-yellow?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Badge"/>
    </a>
    <a href="https://twitter.com/sourab_m">
      <img src="https://img.shields.io/badge/Twitter-blue?style=for-the-badge&logo=twitter&logoColor=white" alt="Twitter Badge"/>
    </a>
  </div>
  <img src="https://komarev.com/ghpvc/?username=pacman100&style=flat-square&color=blue" alt=""/>
  <h1>
    hey there
    <img src="https://media.giphy.com/media/hvRJCLFzcasrR4ia7z/giphy.gif" width="30"/>
  </h1>
</div>
<div align="center">
  <img src="https://media.giphy.com/media/dWesBcTLavkZuG35MI/giphy.gif" width="600" height="300"/>
</div>

### About Me :

I'm Sourab Mangrulkar; a Machine Learning Engineer and Applied Scientist from India üáÆüá≥.

- üî≠ I‚Äôm currently working as a Machine Learning Engineer at [Hugging Face](https://www.huggingface.co/).
- üå± Exploring Natural Language Processing, Computer Vision and Distributed Training at Scale. Always up for meaningful collaboration.
- üòÑ Pronouns: He/His/Him.
- ‚ö° Painting üé®, sketching ‚úçÔ∏è and poetry üìù are my favourite hobbies. Recently, I've started reading up on stocks and economic markets.
- üì´ How to reach me: &nbsp; [![Linkedin Badge](https://img.shields.io/badge/-smangrul-blue?style=flat&logo=Linkedin&logoColor=white)](https://www.linkedin.com/in/sourab-m/)

---
### üìù Research : 
- Arxiv 2023 BigCode Project: [SantaCoder: don't reach for the stars!](https://arxiv.org/abs/2301.03988)
- SIGIR 2022 (eCommerce Workshop): [HISS: A Novel Hybrid Inference Architecture in Embedding Based Product Sourcing using Knowledge Distillation](https://www.amazon.science/publications/hiss-a-novel-hybrid-inference-architecture-in-embedding-based-product-sourcing-using-knowledge-distillation)
- KDD 2022 (ADS Track): [BE3R: BERT-based early-exit using expert routing](https://www.amazon.science/publications/be3r-bert-based-early-exit-using-expert-routing)
- WWW 2022 (Industry Track): [Multilingual Semantic Sourcing using Product Images for Cross-lingual Alignment](https://www.amazon.science/publications/multilingual-semantic-sourcing-using-product-images-for-cross-lingual-alignment)
- SIGDial 2018: [A Context-aware Convolutional Natural Language Generation model for Dialogue Systems](https://aclanthology.org/W18-5020/)



### ‚úçÔ∏è Blog Posts : 
- January 2023: [Finetune LLMs on your own consumer hardware using tools from PyTorch and Hugging Face ecosystem](https://pytorch.org/blog/finetune-llms/)
- December 2023: [Mixture of Experts Explained](https://huggingface.co/blog/moe)
- October 2023: [Personal Copilot: Train Your Own Coding Assistant](https://huggingface.co/blog/personal-copilot)
- October 2023: [Falcon 180B Finetuning using ü§ó PEFT and DeepSpeed](https://medium.com/@sourabmangrulkar/falcon-180b-finetuning-using-peft-and-deepspeed-b92643091d99)
- September 2023: [Fine-tuning Llama 2 70B using PyTorch FSDP](https://huggingface.co/blog/ram-efficient-pytorch-fsdp)
- August 2023: [Large Scale Training of Hugging Face Transformers on TPUs With PyTorch/XLA FSDP](https://pytorch.org/blog/large-scale-training-hugging-face/)
- June 2023: [The Falcon has landed in the Hugging Face ecosystem](https://huggingface.co/blog/falcon)
- May 2023: [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
- February 2023: [ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware
](https://huggingface.co/blog/peft)
- June 2022: [Accelerate Large Model Training using DeepSpeed](https://huggingface.co/blog/accelerate-deepspeed)
- May 2022: [Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel](https://huggingface.co/blog/pytorch-fsdp)

### üí¨ Talks and Presentations
- December 2023: [Hands on session for the ACM Winter School focused on Generative AI](https://github.com/pacman100/acm_winter_school_gen_ai) @ ACM Winter School India Chapter 2023
- December 2023: [Generative AI for All. ü§ó PEFT: Finetuning made simple, efficient and extendable](https://neurips.cc/virtual/2023/competition/66594) @ NeurIPS Conference 2023 -  Large Language Model Efficiency Challenge: 1 LLM + 1GPU + 1Day
- October 2023: [Training a LLaMA in your Backyard: Fine-tuning Very Large Models on Consumer Hardware](https://www.youtube.com/watch?v=v3p574q_yrY&t=661s) @ PyTorch Conference 2023
- August 2023: [Unleashing LLMs: Training, Finetuning, and Evaluating](https://www.analyticsvidhya.com/datahack-summit-2023/workshop/training-finetuning-and-evaluating-llms/) @ DataHack Summit 2023 (Analytics Vidhya)
- August 2023: [Parameter-Efficient Fine-Tuning: Doing more with less](https://www.analyticsvidhya.com/datahack-summit-2023/session/parameter-efficient-fine-tuning-doing-more-with-less/) @ DataHack Summit 2023 (Analytics Vidhya)
<!-- BLOG-POST-LIST:START -->
<!-- BLOG-POST-LIST:END -->


<!-- ### üî• &nbsp; My Stats :
<img src="https://github-readme-stats.vercel.app/api?username=pacman100&&show_icons=true&title_color=ffffff&icon_color=bb2acf&text_color=daf7dc&bg_color=191919">

[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=pacman100&layout=compact&theme=vision-friendly-dark)](https://github.com/anuraghazra/github-readme-stats) -->

